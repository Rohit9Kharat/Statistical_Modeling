{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonparametric statistics are those methods that do not assume a specific distribution to the data.\n",
    "\n",
    "Often, they refer to statistical methods that do not assume a Gaussian distribution. They were developed for use with ordinal or interval data, but in practice can also be used with a ranking of real-valued observations in a data sample rather than on the observation values themselves.\n",
    "\n",
    "A common question about two or more datasets is whether they are different. Specifically, whether the difference between their central tendency (e.g. mean or median) is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis of these tests is often the assumption that both samples were drawn from a population with the same distribution, and therefore the same population parameters, such as mean or median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If after calculating the significance test on two or more samples the null hypothesis is rejected, it indicates that there is evidence to suggest that samples were drawn from different populations, and in turn the difference between sample estimates of population parameters, such as means or medians may be significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value can be interpreted in the context of a chosen significance level called alpha. A common value for alpha is 5% or 0.05. If the p-value is below the significance level, then the test says there is enough evidence to reject the null hypothesis and that the samples were likely drawn from populations with differing distributions.\n",
    "\n",
    "- p <= alpha: reject H0, different distribution.\n",
    "- p > alpha: fail to reject H0, same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1: mean=50.303 stdv=4.426\n",
      "data2: mean=51.764 stdv=4.660\n"
     ]
    }
   ],
   "source": [
    "# generate gaussian data samples\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate two sets of univariate observations\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 51\n",
    "# summarize\n",
    "print('data1: mean=%.3f stdv=%.3f' % (mean(data1), std(data1)))\n",
    "print('data2: mean=%.3f stdv=%.3f' % (mean(data2), std(data2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data does not have the familiar Gaussian distribution, we must resort to nonparametric version of the significance tests. These tests operate in a similar manner, but are distribution free, requiring that real valued data be first transformed into rank data before the test can be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Mann-Whitney U Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mann-Whitney U test is a nonparametric statistical significance test for determining whether two independent samples were drawn from a population with the same distribution.\n",
    "\n",
    "The test was named for Henry Mann and Donald Whitney, although it is sometimes called the Wilcoxon-Mann-Whitney test, also named for Frank Wilcoxon, who also developed a variation of the test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two samples are combined and rank ordered together. The strategy is to determine if the values from the two samples are randomly mixed in the rank ordering or if they are clustered at opposite ends when combined. A random rank order would mean that the two samples are not different, while a cluster of one sample values would indicate a difference between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default assumption or null hypothesis is that there is no difference between the distributions of the data samples. Rejection of this hypothesis suggests that there is likely some difference between the samples. More specifically, the test determines whether it is equally likely that any randomly selected observation from one sample will be greater or less than a sample in the other distribution. If violated, it suggests differing distributions.\n",
    "\n",
    "- Fail to Reject H0: Sample distributions are equal.\n",
    "- Reject H0: Sample distributions are not equal.\n",
    "\n",
    "For the test to be effective, it requires at least 20 observations in each data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests whether the distributions of two independent samples are equal or not.\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "- Observations in each sample are independent and identically distributed (iid).\n",
    "- Observations in each sample can be ranked.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- H0: the distributions of both samples are equal.\n",
    "- H1: the distributions of both samples are not equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat=40.000, p=0.236\n",
      "Probably the same distribution\n"
     ]
    }
   ],
   "source": [
    "# Example of the Mann-Whitney U Test\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "data1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\n",
    "data2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\n",
    "stat, p = mannwhitneyu(data1, data2)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('Probably the same distribution')\n",
    "else:\n",
    "    print('Probably different distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=4025.000, p=0.009\n",
      "Different distribution (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Mann-Whitney U test\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import mannwhitneyu\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate two independent samples\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 51\n",
    "# compare samples\n",
    "stat, p = mannwhitneyu(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Wilcoxon Signed-Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, the data samples may be paired.\n",
    "\n",
    "There are many reasons why this may be the case, for example, the samples are related or matched in some way or represent two measurements of the same technique. More specifically, each sample is independent, but comes from the same population.\n",
    "\n",
    "Examples of paired samples in machine learning might be the same algorithm evaluated on different datasets or different algorithms evaluated on exactly the same training and test data.\n",
    "\n",
    "The samples are not independent, therefore the Mann-Whitney U test cannot be used. Instead, the Wilcoxon signed-rank test is used, also called the Wilcoxon T test, named for Frank Wilcoxon. It is the equivalent of the paired Student T-test, but for ranked data instead of real valued data with a Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wilcoxon signed ranks test is a nonparametric statistical procedure for comparing two samples that are paired, or related. The parametric equivalent to the Wilcoxon signed ranks test goes by names such as the Studentâ€™s t-test, t-test for matched pairs, t-test for paired samples, or t-test for dependent samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default assumption for the test, the null hypothesis, is that the two samples have the same distribution.\n",
    "\n",
    "- Fail to Reject H0: Sample distributions are equal.\n",
    "- Reject H0: Sample distributions are not equal.\n",
    "\n",
    "For the test to be effective, it requires at least 20 observations in each data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests whether the distributions of two paired samples are equal or not.\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "- Observations in each sample are independent and identically distributed (iid).\n",
    "- Observations in each sample can be ranked.\n",
    "- Observations across each sample are paired.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- H0: the distributions of both samples are equal.\n",
    "- H1: the distributions of both samples are not equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat=21.000, p=0.557\n",
      "Probably the same distribution\n"
     ]
    }
   ],
   "source": [
    "# Example of the Wilcoxon Signed-Rank Test\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "data1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\n",
    "data2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\n",
    "stat, p = wilcoxon(data1, data2)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('Probably the same distribution')\n",
    "else:\n",
    "    print('Probably different distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=1886.000, p=0.028\n",
      "Different distribution (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Wilcoxon signed-rank test\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import wilcoxon\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate two independent samples\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 51\n",
    "# compare samples\n",
    "stat, p = wilcoxon(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Kruskal-Wallis H Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with significance tests, such as Mann-Whitney U and the Wilcoxon signed-rank tests, comparisons between data samples must be performed pair-wise.\n",
    "\n",
    "This can be inefficient if you have many data samples and you are only interested in whether two or more samples have a different distribution.\n",
    "\n",
    "The Kruskal-Wallis test is a nonparametric version of the one-way analysis of variance test or ANOVA for short. It is named for the developers of the method, William Kruskal and Wilson Wallis. This test can be used to determine whether more than two independent samples have a different distribution. It can be thought of as the generalization of the Mann-Whitney U test.\n",
    "\n",
    "The default assumption or the null hypothesis is that all data samples were drawn from the same distribution. Specifically, that the population medians of all groups are equal. A rejection of the null hypothesis indicates that there is enough evidence to suggest that one or more samples dominate another sample, but the test does not indicate which samples or by how much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the Kruskal-Wallis H-test leads to significant results, then at least one of the samples is different from the other samples. However, the test does not identify where the difference(s) occur. Moreover, it does not identify how many differences occur. To identify the particular differences between sample pairs, a researcher might use sample contrasts, or post hoc tests, to analyze the specific sample pairs for significant difference(s). The Mann-Whitney U-test is a useful method for performing sample contrasts between individual sample sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fail to Reject H0: All sample distributions are equal.\n",
    "- Reject H0: One or more sample distributions are not equal.\n",
    "\n",
    "Each data sample must be independent, have 5 or more observations, and the data samples can differ in size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests whether the distributions of two or more independent samples are equal or not.\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "- Observations in each sample are independent and identically distributed (iid).\n",
    "- Observations in each sample can be ranked.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- H0: the distributions of all samples are equal.\n",
    "- H1: the distributions of one or more samples are not equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat=0.571, p=0.450\n",
      "Probably the same distribution\n"
     ]
    }
   ],
   "source": [
    "# Example of the Kruskal-Wallis H Test\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "data1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\n",
    "data2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\n",
    "stat, p = kruskal(data1, data2)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('Probably the same distribution')\n",
    "else:\n",
    "    print('Probably different distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=6.051, p=0.049\n",
      "Different distributions (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Kruskal-Wallis H-test\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import kruskal\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate three independent samples\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 50\n",
    "data3 = 5 * randn(100) + 52\n",
    "# compare samples\n",
    "stat, p = kruskal(data1, data2, data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Friedman Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous example, we may have more than two different samples and an interest in whether all samples have the same distribution or not.\n",
    "\n",
    "If the samples are paired in some way, such as repeated measures, then the Kruskal-Wallis H test would not be appropriate. Instead, the Friedman test can be used, named for Milton Friedman.\n",
    "\n",
    "The Friedman test is the nonparametric version of the repeated measures analysis of variance test, or repeated measures ANOVA. The test can be thought of as a generalization of the Kruskal-Wallis H Test to more than two samples.\n",
    "\n",
    "The default assumption, or null hypothesis, is that the multiple paired samples have the same distribution. A rejection of the null hypothesis indicates that one or more of the paired samples has a different distribution.\n",
    "\n",
    "- Fail to Reject H0: Paired sample distributions are equal.\n",
    "- Reject H0: Paired sample distributions are not equal.\n",
    "\n",
    "The test assumes two or more paired data samples with 10 or more samples per group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Friedman test is a nonparametric statistical procedure for comparing more than two samples that are related. The parametric equivalent to this test is the repeated measures analysis of variance (ANOVA). When the Friedman test leads to significant results, at least one of the samples is different from the other samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests whether the distributions of two or more paired samples are equal or not.\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "- Observations in each sample are independent and identically distributed (iid).\n",
    "- Observations in each sample can be ranked.\n",
    "- Observations across each sample are paired.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- H0: the distributions of all samples are equal.\n",
    "- H1: the distributions of one or more samples are not equal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat=0.800, p=0.670\n",
      "Probably the same distribution\n"
     ]
    }
   ],
   "source": [
    "# Example of the Friedman Test\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "data1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\n",
    "data2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\n",
    "data3 = [-0.208, 0.696, 0.928, -1.148, -0.213, 0.229, 0.137, 0.269, -0.870, -1.204]\n",
    "stat, p = friedmanchisquare(data1, data2, data3)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('Probably the same distribution')\n",
    "else:\n",
    "    print('Probably different distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=9.360, p=0.009\n",
      "Different distributions (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Friedman test\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import friedmanchisquare\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate three independent samples\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 50\n",
    "data3 = 5 * randn(100) + 52\n",
    "# compare samples\n",
    "stat, p = friedmanchisquare(data1, data2, data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
